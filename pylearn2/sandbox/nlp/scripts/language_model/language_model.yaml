!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.sandbox.nlp.datasets.penntree.PennTreebank {
        which_set: 'train',
        ngram_size: &ngram_size 7
    },
    model: !obj:pylearn2.models.mlp.MLP {
        layers: [
            !obj:pylearn2.sandbox.nlp.models.mlp.ProjectionLayer {
                layer_name: 'projection',
                dim: 128,
                irange: 0.01
            }, !obj:pylearn2.models.mlp.Tanh {
                layer_name: 'tanh',
                dim: 256,
                irange: 0.01
            }, !obj:pylearn2.models.mlp.Softmax {
                n_classes: 10000,
                layer_name: 'softmax',
                irange: 0.01
            }
        ],
        input_space: !obj:pylearn2.space.IndexSpace {
            dim: 6,
            max_labels: 10000
        }
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        batch_size: 256,
        learning_rate: .1,
        monitoring_dataset: {
            'valid' : !obj:pylearn2.sandbox.nlp.datasets.penntree.PennTreebank {
                which_set: 'valid',
                ngram_size: *ngram_size
            }
        },
        termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased {
            channel_name: 'valid_softmax_nll',
            prop_decrease: 0.,
            N: 10
        },
    },
}
